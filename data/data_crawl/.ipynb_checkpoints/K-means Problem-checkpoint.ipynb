{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6104d9f3",
   "metadata": {},
   "source": [
    "Useful websites for a Data Scientist:\n",
    "\n",
    "* Towards Data Science: https://towardsdatascience.com/\n",
    "* Medium: https://medium.com/\n",
    "* Stack Overflow: https://stackoverflow.com/\n",
    "* Stack Exchange: https://stackexchange.com/\n",
    "* Kaggle: https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fe1f0",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Extract today datetime including day, month, year, hour etc.\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "from pandas_profiling import ProfileReport      # Install pandas_profiling and ipywidgets\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17024b8f",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_csv('marketing_campaign.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report describing our whole dataset. Very time efficient, we are not occupying the notebook with other stuff\n",
    "# It will be generated in the folder we work in\n",
    "report = ProfileReport(df, title=\"Report.html\")\n",
    "report.to_file(\"Report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73892d3",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16940183",
   "metadata": {},
   "source": [
    "##### Datetime Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae654bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substraction between actual year and the column we're working with\n",
    "df['Year_Birth'] = now.year - df['Year_Birth']\n",
    "# Rename column\n",
    "df.rename(columns={'Year_Birth':'Age'}, inplace=True)\n",
    "\n",
    "# Convert the column to datetime\n",
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\n",
    "# Extract year\n",
    "df['Dt_Customer'] = df['Dt_Customer'].dt.year\n",
    "# Do the substraction\n",
    "df['Dt_Customer'] = now.year - df['Dt_Customer']\n",
    "# Rename it\n",
    "df.rename(columns={'Dt_Customer':'Relationship years'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231e10c",
   "metadata": {},
   "source": [
    "##### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to drop this column because most of the customers are having studies\n",
    "df.drop(labels=['Education'], axis=1, inplace=True)\n",
    "\n",
    "# Convert 'Marital_Status' to a binary column. We want only 2 categories -> Single and in a relationship\n",
    "# Convert 'Married' category to 'Together' so we can apply np.where\n",
    "df['Marital_Status'].replace({'Married':'Together'}, inplace=True)\n",
    "df['Marital_Status'] = np.where(df['Marital_Status'] == 'Together', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad529a2",
   "metadata": {},
   "source": [
    "There's nothing we can do about the numerical variables. They look fine in my opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bae0d",
   "metadata": {},
   "source": [
    "##### Drop categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3693d08",
   "metadata": {},
   "source": [
    "We drop them because we must not include  them in a clusterization model. At least not in K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all the columns from our dataframe\n",
    "cols_list = list(df.columns)\n",
    "# Create an empty list where we will append the categorical cols. In our situation there are only binary ones\n",
    "categorical_cols = []\n",
    "\n",
    "for i in cols_list:\n",
    "    # If condition telling it that if the number of categories per column is lower or equal than 2 we append the name\n",
    "    # of the column to categorical_cols list\n",
    "    if len(df[i].value_counts()) <= 2:\n",
    "        categorical_cols.append(i)\n",
    "\n",
    "# Drop categorical columns\n",
    "df.drop(labels=categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Set ID as index\n",
    "df.set_index(keys='ID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419208a",
   "metadata": {},
   "source": [
    "I also decided to drop the columns 'Kidhome' and 'Teenhome' since I consider them as being more categorical than numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['Kidhome', 'Teenhome'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6513f",
   "metadata": {},
   "source": [
    "##### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b344d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULL rows\n",
    "# Create a separate dataframe containing nulls\n",
    "df_nulls = df[df.isna().any(axis=1)]\n",
    "df_nulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c313fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop them since it would be too much to fill the missing ones with the average value of the colum\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Number of rows containing NaN's: {df[df.isna().any(axis=1)].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4141fc2",
   "metadata": {},
   "source": [
    "##### Correlation Matrix after we've cleand our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba88c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "corr = df.corr()\n",
    "sns.heatmap(data=corr, annot=True, cmap=\"Greens\", )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2933c",
   "metadata": {},
   "source": [
    "### Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaled object\n",
    "scaler = StandardScaler()\n",
    "# Create the normalized dataframe\n",
    "df_scaled = pd.DataFrame(data=scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b88fe8",
   "metadata": {},
   "source": [
    "### Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with numbers from 1 to 10\n",
    "number_of_clusters = list(range(1, 11))\n",
    "# SSE Metric list\n",
    "sum_of_squared_distance = []\n",
    "\n",
    "for cluster in number_of_clusters:\n",
    "    kmeans = KMeans(n_clusters=cluster, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    sum_of_squared_distance.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "sns.set(rc={'figure.figsize':(13,7)})\n",
    "\n",
    "plt.plot(number_of_clusters, sum_of_squared_distance, 'go--')\n",
    "plt.xlabel('Number of Clusters', fontsize=13)\n",
    "plt.ylabel('Within Cluster Sum of squares', fontsize=13)\n",
    "plt.title('Elbow Curve to find optimum K', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f58ad6",
   "metadata": {},
   "source": [
    "### Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15,8))\n",
    "for i in list(range(2, 8)):\n",
    "    # Create KMeans instance for different number of clusters\n",
    "    km = KMeans(n_clusters=i, random_state=42)\n",
    "    q, mod = divmod(i, 2)\n",
    "    # Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a427a",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10659c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = list(range(2,11))\n",
    "results  = {}\n",
    "\n",
    "for i in number_of_clusters:\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    labels = kmeans.fit_predict(df_scaled)\n",
    "    db_index = davies_bouldin_score(df_scaled, labels)\n",
    "    results.update({i: db_index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e93055",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "sns.set(rc={'figure.figsize':(13,7)})\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()), 'go--')\n",
    "plt.xlabel('Number of Clusters', fontsize=13)\n",
    "plt.ylabel('Davies-Bouldin Index', fontsize=13)\n",
    "plt.title('Davies-Bouldin Score', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf89c51",
   "metadata": {},
   "source": [
    "### Apply the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d728905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KMeans object having 5 clusters and being named kmeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit_predict(df_scaled)\n",
    "# The below command has been used for visualization purpose only. We want to have a look at the created clusters and\n",
    "# the frequency from each cluster\n",
    "unique, counts = np.unique(kmeans, return_counts=True)\n",
    "# If we have 2 iterables (e.g. lists or tuples) of equal length and need to create a dictionary, we have\n",
    "# to use the zip() function\n",
    "print(f\"Created clusters - {dict(zip(unique, counts))}\")\n",
    "\n",
    "# Create a dataframe for kmeans object\n",
    "clusters = pd.DataFrame({'Clusters' : kmeans})\n",
    "df_clusters = pd.concat([df.reset_index(drop=True), clusters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f876666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the average value for each column of the clusters\n",
    "df_clusters.groupby(['Clusters']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b64cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
