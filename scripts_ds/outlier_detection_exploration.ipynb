{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93da6cdc-6aa2-4393-8b97-97cd73966671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>phenomena</th>\n",
       "      <th>county</th>\n",
       "      <th>pm10_quality</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Banat</td>\n",
       "      <td>['Snow', 'Wind']</td>\n",
       "      <td>TM</td>\n",
       "      <td>51.630000</td>\n",
       "      <td>995.400</td>\n",
       "      <td>-4.095</td>\n",
       "      <td>85.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Dobrogea</td>\n",
       "      <td>['Rain', 'Sleet', 'Wind', 'Snow', 'Flood', 'Fog']</td>\n",
       "      <td>CT</td>\n",
       "      <td>21.520000</td>\n",
       "      <td>1005.875</td>\n",
       "      <td>6.745</td>\n",
       "      <td>96.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>['Snow', 'Frost', 'Rain', 'Sleet', 'Wind', 'Fl...</td>\n",
       "      <td>IS</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>1010.700</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Muntenia</td>\n",
       "      <td>['Snow', 'Sleet', 'Rain', 'Wind', 'Flood', 'Fr...</td>\n",
       "      <td>B</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>998.880</td>\n",
       "      <td>0.252</td>\n",
       "      <td>86.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-20</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>['Wind', 'Snow']</td>\n",
       "      <td>IS</td>\n",
       "      <td>46.050000</td>\n",
       "      <td>1014.100</td>\n",
       "      <td>-1.615</td>\n",
       "      <td>99.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    region                                          phenomena  \\\n",
       "0 2009-02-19     Banat                                   ['Snow', 'Wind']   \n",
       "1 2009-02-19  Dobrogea  ['Rain', 'Sleet', 'Wind', 'Snow', 'Flood', 'Fog']   \n",
       "2 2009-02-19   Moldova  ['Snow', 'Frost', 'Rain', 'Sleet', 'Wind', 'Fl...   \n",
       "3 2009-02-19  Muntenia  ['Snow', 'Sleet', 'Rain', 'Wind', 'Flood', 'Fr...   \n",
       "4 2009-02-20   Moldova                                   ['Wind', 'Snow']   \n",
       "\n",
       "  county  pm10_quality  air_pressure  temperature  humidity  \n",
       "0     TM     51.630000       995.400       -4.095     85.50  \n",
       "1     CT     21.520000      1005.875        6.745     96.75  \n",
       "2     IS     44.600000      1010.700       -0.935     99.00  \n",
       "3      B     34.428571       998.880        0.252     86.20  \n",
       "4     IS     46.050000      1014.100       -1.615     99.50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_excel(\"../data/datasets/dataset_backup.xlsx\")\n",
    "dataset.set_index(['date', 'region', 'phenomena', 'county'], inplace=True)\n",
    "\n",
    "# Display the first few rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5251bb-2553-4991-a0c7-162bbef015c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index(['date', 'region', 'phenomena', 'county'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3c73534-1f3d-4088-9e40-01ea782307b3",
   "metadata": {},
   "source": [
    "### IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e234534-9a28-40d6-8e53-f3dac6230dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mihigh\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "\n",
    "# Fit the model and predict outliers\n",
    "outliers = iso_forest.fit_predict(dataset)\n",
    "\n",
    "# Mark the outliers in the dataset\n",
    "dataset['is_outlier'] = [True if o == -1 else False for o in outliers]\n",
    "\n",
    "# Display the rows that are marked as outliers\n",
    "outlier_data = dataset[dataset['is_outlier'] == True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38598676-3feb-4dc7-b847-77b289dd6c8e",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9256076e-f20e-41f3-ad34-33d7a6faccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# Initialize the One-Class SVM model\n",
    "one_class_svm = OneClassSVM(nu=0.0001, kernel=\"rbf\", gamma='scale')\n",
    "\n",
    "# Fit the model and predict outliers\n",
    "svm_outliers = one_class_svm.fit_predict(scaled_data)\n",
    "\n",
    "# Mark the outliers in the dataset\n",
    "dataset['svm_is_outlier'] = [True if o == -1 else False for o in svm_outliers]\n",
    "\n",
    "# Display the rows that are marked as outliers by One-Class SVM\n",
    "svm_outlier_data = dataset[dataset['svm_is_outlier'] == True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "428aa6b2-0766-44b0-9aed-ecf485bb1880",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3602605-053c-4622-98ea-bb0bc556b450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18387, 6), (4597, 6))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val = train_test_split(scaled_data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "602e771e-6f6d-42d1-ad3d-d75af04833a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define VAE architecture parameters\n",
    "input_dim = X_train.shape[1]\n",
    "intermediate_dim = 10\n",
    "latent_dim = 2\n",
    "\n",
    "# Encoder architecture\n",
    "inputs = Input(shape=(input_dim,), name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# Reparameterization trick to sample z values\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# Decoder architecture\n",
    "decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
    "decoder_mean = Dense(input_dim, name='decoder_mean')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# VAE model\n",
    "vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "# Define VAE loss\n",
    "xent_loss = input_dim * mse(inputs, x_decoded_mean)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# Compile the model\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce43abe2-4b82-4fb6-9ebd-9a9b3bf9649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute Reconstruction\n",
    "reconstructed_data = vae.predict(X_val)\n",
    "\n",
    "# Step 2: Calculate Reconstruction Error (MSE)\n",
    "mse_errors = np.mean(np.square(X_val - reconstructed_data), axis=1)\n",
    "\n",
    "# Step 3: Set a Threshold\n",
    "# Here, we can use a high percentile (e.g., 95th percentile) of the MSE as a threshold\n",
    "threshold = np.percentile(mse_errors, 95)\n",
    "\n",
    "# Flag data points as outliers based on the threshold\n",
    "outliers_vae = np.where(mse_errors > threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac982209-ebd8-446f-89c3-a48f1a42c380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63726389,  0.47673483, -0.73458078,  0.98946019, -0.22949978,\n",
       "        -0.22939472],\n",
       "       [-1.14284805,  0.18467055, -0.43843936, -0.05498435, -0.22949978,\n",
       "        -0.22939472],\n",
       "       [-0.4050231 ,  0.57073791,  0.46994152, -0.03764917, -0.22949978,\n",
       "        -0.22939472],\n",
       "       ...,\n",
       "       [ 0.33920306, -1.41595395,  0.70566922,  1.67853355, -0.22949978,\n",
       "        -0.22939472],\n",
       "       [-0.02196057, -1.54134984,  0.86526802,  0.24838128, -0.22949978,\n",
       "        -0.22939472],\n",
       "       [ 1.9511075 ,  0.03828765, -2.08597747, -1.03875576,  4.35730272,\n",
       "        -0.22939472]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ed6ca79-e1c7-45c8-ac80-f54d05617480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train and X_val back to DataFrames to retrieve original indices\n",
    "X_train_df = pd.DataFrame(X_train, index=dataset.index[:len(X_train)])\n",
    "X_val_df = pd.DataFrame(X_val, index=dataset.index[len(X_train):])\n",
    "\n",
    "# Retrieve the original indices of the outliers from the validation set DataFrame\n",
    "original_indices_vae = X_val_df.iloc[outliers_vae].index\n",
    "\n",
    "# Extract the outlier rows from the original dataset\n",
    "outlier_rows_vae = dataset.loc[original_indices_vae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c333fe-62d4-441f-bc6e-f6f6f3130bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
